# Live2D-LLM-Local-Assistant (Live2D AI 桌面看板娘)

<img width="382" height="372" alt="image" src="https://github.com/user-attachments/assets/325407a3-0fbf-401b-8463-8d1c432a281d" />

这是一个基于 Python (FastAPI + PyQt5) 和 Web 技术构建的智能化桌面看板娘挂件。它不仅能让 Live2D 模型在你的桌面上“活”过来，还深度集成了本地 LLM (如 Ollama) 支持，让看板娘具备了“大脑”和“眼睛”，能够与你进行多轮对话、分析你的屏幕内容，甚至通过 AI 控制自身的表情与动作。

---

## ✨ 功能特性 (Features)

本项目集成了桌面交互、AI 智能与开发调试三大核心板块：

### 🖥️ 桌面交互体验
*   **沉浸式挂件**：无边框、背景完美透明，支持**鼠标点击穿透**（可作为纯装饰），支持**窗口置顶**。
*   **灵活控制**：通过系统托盘图标管理服务，支持**鼠标拖拽移动**（需在设置中解锁）、位置/大小重置防丢失。
*   **智能交互**：支持鼠标视线跟随，点击身体/头部触发特定动作，闲置状态自动进入睡眠模式。
*   **兼容性渲染**：提供 **DirectX 9 (D3D9)**、**Software OpenGL** 等多种渲染模式，完美适配老旧显卡或驱动冲突的新电脑，解决闪烁/黑屏问题。

### 🤖 LLM & 视觉能力 (AI Power)
*   **本地大模型接入**：完美支持 **Ollama** 本地接口，数据隐私更安全；同时也兼容 OpenAI 格式的在线 API。
*   **多轮对话记忆**：看板娘拥有“记忆”，支持长对话，并提供**聊天记录的导出与导入**功能。
*   **视觉分析 (Peek)**：
    *   **屏幕吐槽 (Roast)**：一键截取当前屏幕或指定窗口，让看板娘根据画面内容对你进行“吐槽”或互动。
    *   **聊天助手 (Chat)**：分析屏幕上的聊天记录或文档，辅助你生成高情商回复。
*   **图文多模态**：在普通对话中支持上传图片，模型可同时理解文字与图片内容。

### 🔧 高级调试与开发
*   **双模设置面板**：
    *   **Python 原生面板**：精准控制窗口坐标、尺寸、渲染模式及开机自启。
    *   **Web 高级面板**：配置模型参数、API Key、提示词 (Prompt) 及查看历史记录。
*   **动作调试实验室**：
    *   支持枚举模型的所有**表情 (Expressions)** 和 **动作 (Motions)**。
    *   支持**Raw Data 调试**：直接输入 `.mtn` 动作文件数据让模型执行，方便开发者测试。
*   **开机自启**：支持一键设置 Windows 开机自动启动（基于 VBS 脚本，无黑框）。

---

## ⚠️ 免责声明 (Disclaimer)

> **请务必阅读以下内容：**
>
> 1.  **仅供学习交流**：本项目及其包含的代码、模型资源仅供个人学习、研究和技术交流使用。
> 2.  **禁止商业用途**：**不得**将本项目或其中的模型用于任何形式的商业用途。
> 3.  **免责条款**：使用本项目造成的任何法律责任、数据丢失或系统问题均由使用者自行承担，本人（开发者）不承担任何连带责任。
> 4.  **模型版权**：项目中使用的 Live2D 模型版权归原作者所有，请遵守原作者的使用协议。
> 5.  **隐私与数据**：使用 Ollama 本地 API 时，项目不会通过互联网获得或分享您本机内的任何内容，不会通过互联网下载任何内容至您本机；若您使用外部 API 接口，在使用与屏幕截图相关的内容时，您的屏幕截图会被发送至对应 API 接口，因此造成的隐私泄露或其他问题，本人（开发者）不承担任何责任。

---

## 🦙 Ollama 配置指南 (推荐)

为了获得最佳的响应速度和隐私保护，推荐配合 [Ollama](https://ollama.com/) 本地运行大模型。

### 1. 安装与准备
请前往 [Ollama 官网](https://ollama.com/) 下载并安装 Ollama。

### 2. 模型推荐与拉取
为了在普通电脑上也能获得极速体验（文字回复 < 3秒，识图 < 10秒），推荐使用 **Qwen 3vl (Instruct)** 或 **Llama 3.2** 的轻量化版本。

打开终端 (CMD/PowerShell) 运行以下命令拉取模型：

*   **推荐（速度快/效果好）**
    ```bash
    ollama run qwen3-vl:2b-instruct
    # 或者
    ollama run qwen3-vl:8b-instruct
    ```
### 3. 软件内配置
启动看板娘后，在设置面板 -> **LLM设置** 中：
*   **API 地址**：默认为 `http://127.0.0.1:11434/v1/chat/completions`
*   **模型选择**：点击“刷新列表”，选择刚刚拉取的 `qwen3vl:2b-instruct`。

> **🔔 性能提示**：
> *   **冷启动延迟**：重启 Ollama 服务或重启电脑后，第一次对话可能需要 **几十秒到几分钟** 将模型加载进内存，请耐心等待。之后的对话将非常迅速。
> *   **显存占用**：请确保您的显存/内存足够运行所选参数量的模型。

---

## 🚀 快速开始 (运行)

本项目提供了内置的 Python 运行环境（绿色版），**无需在您的电脑上安装 Python** 即可运行。

### 启动方式
直接双击运行根目录下的脚本：
```text
boot.vbs
```
*程序启动后没有任何黑框，会在系统托盘显示图标，看板娘将出现在屏幕右下角。*

---

## 🎨 添加与管理模型

本程序支持加载标准的 Live2D 模型。

1.  **导入文件**：将您的模型文件夹拖入 `live2d_api-master/model/` 目录下。
2.  **配置列表**：修改 `live2d_api-master/model/model_list.json` 文件（或 `static-api-file.json`），将新模型的路径添加进去。
3.  **生成索引**：如果模型较多，可运行辅助脚本自动生成配置文件：
    *   *需使用内置环境运行：* `runtime\python.exe gene-config-file.py`
4.  **刷新**：在软件设置面板或浏览器中刷新模型列表即可看到新模型。

---

## 💻 浏览器访问与调试

除了桌面挂件模式，您也可以通过本地浏览器直接访问看板娘页面，用于调试模型动作或网页逻辑。

*   **访问地址**：[http://127.0.0.1:10452/live2d.html](http://127.0.0.1:10452/live2d.html)
*   **调试建议**：
    *   推荐使用 Chrome 或 Edge 浏览器。
    *   按 `F12` 打开开发者工具。
    *   **注意**：调试时请在“网络 (Network)”选项卡中**勾选“禁用缓存 (Disable cache)”**，以确保修改实时生效。

---

## 🛠️ 环境配置与开发 (高级)

如果您是开发者，希望使用自己的 Python 环境，或者需要更新内置环境的依赖。

### 1. 使用本地 Python 环境运行

如果您电脑中已安装 Python 并且不想使用内置的 `runtime`：

1.  请确保安装了 `requirements.txt` 中的所有依赖。
2.  运行以下脚本启动：
    ```text
    boot_lr.vbs
    ```
3.  **关于开机自启**：如果您使用本地 Python 环境，**请勿**在软件设置面板中勾选“开机自动启动”（那是为内置环境设计的）。请手动将 `boot_lr.vbs` 的快捷方式放入 Windows 的启动目录 (`shell:startup`) 中。

### 2. 更新/安装内置环境依赖

如果您需要为内置的嵌入式 Python (`runtime` 目录) 安装新的库，请在项目根目录下打开 CMD (终端)，并依次执行以下命令：

```cmd
:: 清除环境变量干扰，防止读取到系统的 Python
set PYTHONPATH=
set PYTHONHOME=

:: 使用隔离模式 (-I) 安装依赖到 runtime 环境
runtime\python.exe -I -m pip install -r requirements.txt
```

---

## 🔗 致谢与引用 (Credits)

本项目参考并引用了以下开源项目及文章，特此感谢原作者的贡献：

1.  **FGHRSH Blog** - Live2D 看板娘原理与实现：
    *   [https://www.fghrsh.net/post/123.html](https://www.fghrsh.net/post/123.html)
2.  **fghrsh/live2d_demo** - 基础 Web 端实现参考：
    *   [https://github.com/fghrsh/live2d_demo](https://github.com/fghrsh/live2d_demo)
3.  **panedioic/live2d_demo_without_api** - 本地化 API 实现参考：
    *   [https://github.com/panedioic/live2d_demo_without_api](https://github.com/panedioic/live2d_demo_without_api)
